WEBVTT

00:00:00.001 --> 00:00:02.360
Hello everyone, my name is Zsolt Krémer, I'm a

00:00:02.360 --> 00:00:05.200
PhD student from the Budapest University of

00:00:05.200 --> 00:00:06.000
Technology and Economics,

00:00:06.000 --> 00:00:09.680
and I'm going to present our paper titled "Cooperative

00:00:09.680 --> 00:00:12.530
Performance Enhancement Using Quick Tunneling in

00:00:12.530 --> 00:00:14.000
5G Cellular Networks".

00:00:14.000 --> 00:00:17.600
The other authors are Mirja Külavin, Markus Ilar

00:00:17.600 --> 00:00:20.000
and Attila Mihály from Ericsson.

00:00:20.000 --> 00:00:24.050
5G is going to bring very high peak data rates

00:00:24.050 --> 00:00:27.000
and significantly lower latency,

00:00:27.000 --> 00:00:30.510
however the propagation properties of the new

00:00:30.510 --> 00:00:34.500
radio also result in higher volatility in

00:00:34.500 --> 00:00:37.000
available bandwidth.

00:00:37.000 --> 00:00:41.310
Previous studies showed that these factors intensify

00:00:41.310 --> 00:00:44.590
the need for a shorter control loop and local

00:00:44.590 --> 00:00:47.000
optimizations in the transport layer.

00:00:48.000 --> 00:00:53.460
In LTE networks, this has been mostly achieved by

00:00:53.460 --> 00:00:58.000
performance enhancing proxies, which basically

00:00:58.000 --> 00:01:01.950
split the end-to-end connection into two separate

00:01:01.950 --> 00:01:06.000
control loops for the two separate domains.

00:01:06.000 --> 00:01:10.910
QUIC has recently been standardized as RFC 9000

00:01:10.910 --> 00:01:15.000
and it is already widely deployed by Google.

00:01:15.000 --> 00:01:18.040
It is expected that the traffic share of the

00:01:18.040 --> 00:01:21.410
protocol is going to increase rapidly after the

00:01:21.410 --> 00:01:23.000
standardization.

00:01:23.000 --> 00:01:26.560
It's a fully encrypted transport protocol,

00:01:26.560 --> 00:01:30.000
achieving an enhanced privacy for end-users.

00:01:30.000 --> 00:01:33.780
However, this end-to-end encryption also makes

00:01:33.780 --> 00:01:37.290
connection splitting solutions not feasible

00:01:37.290 --> 00:01:38.000
anymore.

00:01:38.000 --> 00:01:41.420
So a new approach is needed to enable network-assisted

00:01:41.420 --> 00:01:45.000
performance optimization for encrypted protocols.

00:01:45.000 --> 00:01:49.560
What we propose is a cooperative performance

00:01:49.560 --> 00:01:52.000
enhancement framework,

00:01:52.000 --> 00:01:57.330
using MASQ as the signaling protocol towards the

00:01:57.330 --> 00:02:01.000
proxy, resulting in two layers of connections,

00:02:01.000 --> 00:02:06.120
a QUIC tunnel between the client and the proxy,

00:02:06.120 --> 00:02:08.550
and the end-to-end QUIC connection between the

00:02:08.550 --> 00:02:11.000
client and the target application server.

00:02:11.000 --> 00:02:15.160
It is important to note that the security context

00:02:15.160 --> 00:02:19.000
of the end-to-end connection is unmodified,

00:02:19.000 --> 00:02:22.840
so confidentiality, source authentication and

00:02:22.840 --> 00:02:25.000
integrity is preserved.

00:02:26.000 --> 00:02:30.680
Explicit consent is required for requesting a

00:02:30.680 --> 00:02:33.000
service from the proxy.

00:02:33.000 --> 00:02:39.070
And the separation of communication channel data

00:02:39.070 --> 00:02:44.000
and tunnel data is possible by maintaining

00:02:44.000 --> 00:02:48.000
separate QUIC streams in the same QUIC connection.

00:02:49.000 --> 00:02:52.890
Overall, this design proves that it is possible

00:02:52.890 --> 00:02:56.270
to provide proxy services without violating the

00:02:56.270 --> 00:02:59.360
end-to-end principle of the transport and

00:02:59.360 --> 00:03:01.000
application layers.

00:03:01.000 --> 00:03:05.140
We have identified three different use cases,

00:03:05.140 --> 00:03:08.020
based on a different granularity of cooperation

00:03:08.020 --> 00:03:11.000
between the server, the client and the proxy,

00:03:11.000 --> 00:03:14.280
and these are local loss recovery, promise

00:03:14.280 --> 00:03:18.090
signaling and sending declarative messages to the

00:03:18.090 --> 00:03:19.000
server.

00:03:19.000 --> 00:03:24.710
When the client requests the local loss recovery

00:03:24.710 --> 00:03:26.000
feature,

00:03:26.000 --> 00:03:30.920
it is done by using the reliable data stream

00:03:30.920 --> 00:03:34.000
service of the QUIC tunnel,

00:03:34.000 --> 00:03:37.950
and besides this initial explicit request, no

00:03:37.950 --> 00:03:41.000
additional signaling is needed.

00:03:41.000 --> 00:03:45.500
Although packet losses are considered rare in 4G

00:03:45.500 --> 00:03:50.000
and 5G networks when using acknowledged mode,

00:03:50.000 --> 00:03:54.950
this use case can improve the performance of unacknowledged

00:03:54.950 --> 00:04:01.000
mode as well, and thus enable lower latency.

00:04:01.000 --> 00:04:04.280
On the right, you can see some preliminary

00:04:04.280 --> 00:04:12.000
performance results using 1% emulated random loss,

00:04:12.000 --> 00:04:17.480
and you can see that the average download time is

00:04:17.480 --> 00:04:21.930
significantly lower when the local loss recovery

00:04:21.930 --> 00:04:24.000
feature of the proxy is used,

00:04:24.000 --> 00:04:29.000
especially if the RTT increases.

00:04:30.000 --> 00:04:33.400
Promise signaling is useful if the bottleneck is

00:04:33.400 --> 00:04:36.000
between the client and the proxy.

00:04:36.000 --> 00:04:40.880
The proxy is able to send a so-called promise

00:04:40.880 --> 00:04:45.850
signal, which indicates the reception of a packet

00:04:45.850 --> 00:04:47.000
by the proxy,

00:04:47.000 --> 00:04:51.440
and then the client can progressively acknowledge

00:04:51.440 --> 00:04:55.000
these promised packets to the server.

00:04:56.000 --> 00:04:59.570
So this allows the proxy to buffer a sufficient

00:04:59.570 --> 00:05:01.000
number of packets,

00:05:01.000 --> 00:05:04.220
and then quickly send them to the client if the

00:05:04.220 --> 00:05:06.000
capacity increases.

00:05:06.000 --> 00:05:09.050
This is similar to how split connection

00:05:09.050 --> 00:05:13.000
performance enhancing proxies operate today.

00:05:13.000 --> 00:05:16.650
The third use case is sending declarative

00:05:16.650 --> 00:05:19.000
messages to the server.

00:05:19.000 --> 00:05:24.650
This assumes another explicit tunnel between the

00:05:24.650 --> 00:05:27.000
proxy and the server,

00:05:27.000 --> 00:05:32.040
and then the proxy is able to send declarative "safe

00:05:32.040 --> 00:05:36.830
to ignore" messages containing acknowledgement or

00:05:36.830 --> 00:05:38.000
even NAC info,

00:05:38.000 --> 00:05:44.000
and the server can then utilize these acknowledgements

00:05:44.000 --> 00:05:47.990
and apply a multi-domain congestion control

00:05:47.990 --> 00:05:49.000
algorithm,

00:05:49.000 --> 00:05:52.300
which maintains two separate control loops for

00:05:52.300 --> 00:05:55.000
the wired and the wireless domains.

00:05:55.000 --> 00:05:57.900
One of them is clocked by the acknowledgements

00:05:57.900 --> 00:05:59.000
from the proxy,

00:05:59.000 --> 00:06:01.770
the other one clocked by the acknowledgements

00:06:01.770 --> 00:06:03.000
from the client.

00:06:03.000 --> 00:06:06.070
One of them can be more conservative and the

00:06:06.070 --> 00:06:08.000
other one more aggressive,

00:06:08.000 --> 00:06:11.630
and thus the algorithm is able to provide both

00:06:11.630 --> 00:06:15.340
fairness in the wired domain and fast utilization

00:06:15.340 --> 00:06:17.000
in the wireless domain.

00:06:17.000 --> 00:06:21.740
On the right, there are some early results using

00:06:21.740 --> 00:06:28.000
the millimeter wave module of the NS3 simulator,

00:06:28.000 --> 00:06:32.680
and it can be seen that multi-domain congestion

00:06:32.680 --> 00:06:37.000
control outperforms QUBIC significantly,

00:06:37.000 --> 00:06:43.320
especially if the RTT of the internet link

00:06:43.320 --> 00:06:45.000
increases,

00:06:45.000 --> 00:06:52.470
with both using the CODEL AQM and the fixed 7MB

00:06:52.470 --> 00:06:56.000
drop-tail buffer.

00:06:56.000 --> 00:07:01.070
In conclusion, transparent connection-splitting

00:07:01.070 --> 00:07:04.650
performance-enhancing proxies are not going to be

00:07:04.650 --> 00:07:08.000
feasible for encrypted traffic.

00:07:08.000 --> 00:07:12.140
We have proposed a cooperative performance-enhancing

00:07:12.140 --> 00:07:15.000
framework based on the MASQ protocol,

00:07:15.000 --> 00:07:20.000
built on explicit consensus by the endpoint,

00:07:20.000 --> 00:07:24.420
and maintaining an unmodified security context of

00:07:24.420 --> 00:07:28.000
the original end-to-end connection.

00:07:28.000 --> 00:07:32.390
We have shown three different use cases, local

00:07:32.390 --> 00:07:35.350
loss recovery, promise signaling, and declarative

00:07:35.350 --> 00:07:37.000
messages to the server,

00:07:37.000 --> 00:07:42.000
shown some promising early performance results,

00:07:42.000 --> 00:07:46.200
and our future work mainly focuses on a detailed

00:07:46.200 --> 00:07:50.500
performance evaluation in 4G and 5G network

00:07:50.500 --> 00:07:52.000
conditions.

00:07:52.000 --> 00:07:54.000
Thank you for your attention.

